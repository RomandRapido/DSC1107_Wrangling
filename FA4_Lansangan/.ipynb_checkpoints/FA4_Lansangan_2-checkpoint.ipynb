{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN and bias-variance tradeoff\n",
    "### Setup: Apply Farming\n",
    "You own a square apple orchard, measuring 200 meters on each side. You have planted trees in a grid ten meters apart from each other. Last apple season, you measured the yield of each tree in your orchard (in average apples per week). You noticed that the yield of the different trees seems to be higher in some places of the orchard and lower in others, perhaps due to differences in sunlight and soil fertility across the orchard.\n",
    "\n",
    "Unbeknownst to you, the yield $Y$ of the tree planted $E_1$ meters to the right and $E_2$ meters up from the bottom left-hand corner of the orchard has distribution $Y = ƒ (E) + \\epsilon$, where\n",
    "\n",
    "$$\n",
    "f(E) = 50 + 0.001E_1^2 + 0.001E_2^2 , \\epsilon ~ N(0, \\sigma^2), \\sigma = 4\n",
    "$$\n",
    "\n",
    "The data you collected are as in Figure 1.\n",
    "The underlying trend is depicted in Figure 2, with the top right-hand corner of the orchard being more fruitful.\n",
    "\n",
    "### 2.1 2.1\tA simple rule to predict this season’s yield (15 points)\n",
    "\n",
    "This apple season is right around the corner, and you’d like to predict the yield of each tree. You come up with perhaps the simplest possible prediction rule: predict this year’s yield for any given tree based on last year’s yield from that same tree. Without doing any programming, answer the following questions:\n",
    "\n",
    "1.\tWhat is the training error of such a rule?\n",
    "\n",
    "Since we are just taking the last year's yield to predict the future yield, the training error would be 0. Because we are essentially copying each data point and turning it into predition.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{Training Error} &= \\frac{1}{n} \\sum^n_{i=1} (f(E_i) - \\hat{f}(E_i)) \\\\\n",
    "&= \\frac{1}{n} \\sum^n_{i=1} (f(E_i) - f(E_i)) \\\\\n",
    "&= \\frac{1}{n} \\times 0 = 0\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "*Training Error* could also be calle\n",
    "2.\tWhat is the mean squared bias, mean variance, and expected test error of this prediction rule?\n",
    "\n",
    "##### For the mean squared bias:\n",
    "\n",
    "$$\n",
    "\\text{Mean Squared Bias} = \\frac{1}{n}\\sum_{i=1}^n(E[\\hat{f}(x_i)] - f(x_i))^2\n",
    "$$\n",
    "\n",
    "Note that $Y_{last} = f(x) + \\epsilon_{last}$\n",
    "\n",
    "So \n",
    "\n",
    "$E[Y_{last}] = E[f(x) + \\epsilon_{last}] = f(x) + E[\\epsilon_{last}]$ \n",
    "\n",
    "and since \n",
    "\n",
    "$\\epsilon \\sim N(0, \\sigma^2)$, \n",
    "\n",
    "$E[Y_{last}] = f(x)$\n",
    "\n",
    "\n",
    "Thus applying the rule of predicting the yield based solely on last year's yield will give us\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{Mean Squared Bias} &= \\frac{1}{n}\\sum_{i=1}^n(E[Y_{i,last}] - f(x_i))^2 \\\\\n",
    "&= \\frac{1}{n} \\sum_{i=1}^n (f(x_i) - f(x_i))^2 = 0\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "##### For Mean Variance\n",
    "\n",
    "As was derrived earlier ($Y_{last}$),\n",
    "\n",
    "$Var(Y_{last}) = Var(f(x) - \\epsilon_{last}) = Var(\\epsilon_{last})$. \n",
    "\n",
    "This is true because $f(x)$ is a deterministic function for x. So Var(f(x)) = 0. \n",
    "\n",
    "And $Var(\\epsilon_{last}) = \\sigma^2$ based on given. \n",
    "\n",
    "Thus, $Var(Y_{last}) = \\sigma^2 = 4^2 = 16$.\n",
    "\n",
    "Therefore the Mean Variance:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{Mean Variance} &= \\frac{1}{n}\\sum_{i=1}^n(Var(x_i)) \\\\\n",
    "&= \\frac{1}{n} \\sum_{i=1}^n (16) \\\\\n",
    "&= \\frac{1}{n} \\times 16n \\\\ \n",
    "&= 16\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "#### For Expected Test Error\n",
    "\n",
    "$$\n",
    "\\text{ETE} = \\text{Mean Squared Bias} + \\text{Mean Variance} + \\text{Irreductible Error}\n",
    "$$\n",
    "\n",
    "Note that the Irreductible Error in Y is the variance of the $\\epsilon$ term. Therefore,\n",
    "\n",
    "$Var(\\epsilon) = \\sigma^2 = 4^2 = 16$\n",
    "\n",
    "So, \n",
    "$$\n",
    "\\text{ETE} = 0 + 16 + 16 = 32\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tWhy is this not the best possible prediction rule?\n",
    "\n",
    "Determining the future yield using last year's yield on the same tree isn't the best possible prediction rule because it adds 16 from variance to the already noisy irreductible error of 16. This type of modeling captures the irreductible noise/error in our training data and treat it as essential in our predictive function. This isn't ideal because we only want to get the true function to predict the response. It intrudces a new room for error that is the same size as what is unavoidable, irreductible error. Thus making the room for error twice as large when predicting for other dataset outside of the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2\tK-nearest neighbors regression (conceptual) (15 points)\n",
    "\n",
    "As a second attempt to predict a yield for each tree, you average together last year’s yields of the K trees closest to it (including itself, and breaking ties randomly if necessary). So if you choose K = 1, you get back the simple rule from the previous section. This more general rule is called K-nearest neighbors (KNN) regression (see ISLR p. 105).\n",
    "\n",
    "KNN is not a parametric model like linear or logistic regression, so it is a little harder to pin down its degrees of freedom.\n",
    "\n",
    "1.\tWhat happens to the model complexity as K increases? Why?\n",
    "\n",
    "As K increases, the K-nearest neighbor model becomes less complex because the decision boundary becomes smoother and less sensitive to individual data points. While larger K requires considering more neighbors for each prediction, this does not involve estimating additional parameters. Instead, it averages over more observations, reducing overfitting and simplifying the model’s behavior.\n",
    "\n",
    "2. The degrees of freedom for KNN is sometimes considered n/K, where n is the training set size. Why might this be the case? [Hint: consider a situation where the data are clumped in groups of K.]\n",
    "\n",
    "First and foremost, let us ask ourselves \"what's the purpose and implication of degrees of freedom?\".  \n",
    "\n",
    "Degrees of freedom  indicates the amount of free variables we have in a model. How many variables can freely choose what values they contain, as the name suggests. \n",
    "\n",
    "In K Nearest Neightbhor, we are essentially turning the N data points into clusters of size K. Therefore, the larger K, the less degrees of freedom we have because we are dividing the N points by K, clustering the K nearest points to act as a single unit.\n",
    "\n",
    "For example, N=100 and K=5. The model will behave as if it has 20 Independent Data Points because we have clustered the N into 20 groups with K size.\n",
    "\n",
    "TLDR, in clustering the data points into groups with K size, we are reducing the number of (acting) data points. So each  K individual data points nearest to each other will only have one representation in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\t\tConceptually, why might increasing K tend to improve the prediction rule? What does this have to do with the bias-variance tradeoff?\n",
    "\n",
    "Compere to K=1, increasing K will tend to improve the prediction rule because we are considering the average yield in a specific area. For K=1, we have low bias and high variance. In such case, we are capturing everythign in our data points, including the noises. We are essentially overfitting here. This isn't good if we are trying to generalize the data points outside of the training dataset. If we increase the K, we will increase the bias and will decrease the variance. This ought to reduce the noise captured and only leave us with the essential predictive function of the model.\n",
    "\n",
    "4. Conceptually, why might increasing K tend to worsen the prediction rule? What does this have to do with the bias-variance tradeoff?\n",
    "\n",
    "However, if we keep increasing the K further than we ought to do, it will worsen the model in a sense that our model will now become underfitted. Meaning, our model will have high bias and low variance. It's the opposite but as problematic as underfitting because we our loosing essential variety in our model. Meaning, the true predictive function in our data is being treated as noise. This is vast over-generalization. This just one way of telling our model to average all data points and return the calculated average as prediction every time, regardless of data points (this is called as a base model).\n",
    "\n",
    "The key for a good model is to find the sweet spot between variance and bias, essentially minimizing bias + variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3\tK-nearest neighbors regression (simulation) (25 points)\n",
    "Now, we try KNN for several values of K. For each value of K, we use a numerical simulation to compute the bias and variance for every tree in the orchard. These results are contained in training_results_summary below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE:  (6174, 5)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6174 entries, 0 to 6173\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   K         6174 non-null   float64\n",
      " 1   X1        6174 non-null   float64\n",
      " 2   X2        6174 non-null   float64\n",
      " 3   bias      6174 non-null   float64\n",
      " 4   variance  6174 non-null   float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 241.3 KB\n",
      "INFO:  None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>bias</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>16.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.140</td>\n",
       "      <td>12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.109</td>\n",
       "      <td>15.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-0.566</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     K   X1    X2   bias  variance\n",
       "0  1.0  0.0   0.0 -0.250      16.2\n",
       "1  1.0  0.0  10.0  0.140      12.2\n",
       "2  1.0  0.0  20.0 -0.523      20.4\n",
       "3  1.0  0.0  30.0  0.109      15.6\n",
       "4  1.0  0.0  40.0 -0.566      21.4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyreadr\n",
    "import pandas as pd\n",
    "\n",
    "result = pyreadr.read_r('training_results_summary.rds')\n",
    "df = result[None]\n",
    "print(\"SHAPE: \", df.shape)\n",
    "print(\"INFO: \", df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "K\n",
       "4.0     662\n",
       "1.0     651\n",
       "5.0     644\n",
       "10.0    631\n",
       "8.0     613\n",
       "2.0     611\n",
       "3.0     601\n",
       "9.0     591\n",
       "7.0     586\n",
       "6.0     584\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['K'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>bias</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6174.00000</td>\n",
       "      <td>6174.0</td>\n",
       "      <td>6174.000000</td>\n",
       "      <td>6174.000000</td>\n",
       "      <td>6174.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.45562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.980564</td>\n",
       "      <td>0.002458</td>\n",
       "      <td>17.589714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.88489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.727389</td>\n",
       "      <td>0.498698</td>\n",
       "      <td>4.305599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.059342</td>\n",
       "      <td>10.000889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>-0.332027</td>\n",
       "      <td>13.951560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.002586</td>\n",
       "      <td>17.635789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.339294</td>\n",
       "      <td>21.317773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.971670</td>\n",
       "      <td>24.999702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                K      X1           X2         bias     variance\n",
       "count  6174.00000  6174.0  6174.000000  6174.000000  6174.000000\n",
       "mean      5.45562     0.0    44.980564     0.002458    17.589714\n",
       "std       2.88489     0.0    28.727389     0.498698     4.305599\n",
       "min       1.00000     0.0     0.000000    -2.059342    10.000889\n",
       "25%       3.00000     0.0    20.000000    -0.332027    13.951560\n",
       "50%       5.00000     0.0    40.000000     0.002586    17.635789\n",
       "75%       8.00000     0.0    70.000000     0.339294    21.317773\n",
       "max      10.00000     0.0    90.000000     1.971670    24.999702"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tCreate a new tibble called overall_results the contains the mean squared bias, mean variance, and expected test error for each value of K. This tibble should have four columns: K, mean_sq_bias, mean_variance, and expected_test_error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_function(X1, X2):\n",
    "    return 50+ 0.001*X1**2 + 0.001*X2**2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias_sq_mean</th>\n",
       "      <th>variance_mean</th>\n",
       "      <th>expected_test_error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.279816</td>\n",
       "      <td>17.487842</td>\n",
       "      <td>33.767657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.256027</td>\n",
       "      <td>17.351614</td>\n",
       "      <td>33.607641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.226636</td>\n",
       "      <td>17.690798</td>\n",
       "      <td>33.917434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.264448</td>\n",
       "      <td>17.724236</td>\n",
       "      <td>33.988684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.255017</td>\n",
       "      <td>17.768730</td>\n",
       "      <td>34.023747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>0.252016</td>\n",
       "      <td>17.326262</td>\n",
       "      <td>33.578278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>0.244077</td>\n",
       "      <td>17.710189</td>\n",
       "      <td>33.954266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>0.231901</td>\n",
       "      <td>17.563369</td>\n",
       "      <td>33.795270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>0.232287</td>\n",
       "      <td>17.641304</td>\n",
       "      <td>33.873590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.240127</td>\n",
       "      <td>17.614474</td>\n",
       "      <td>33.854601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      bias_sq_mean  variance_mean  expected_test_error\n",
       "K                                                     \n",
       "1.0       0.279816      17.487842            33.767657\n",
       "2.0       0.256027      17.351614            33.607641\n",
       "3.0       0.226636      17.690798            33.917434\n",
       "4.0       0.264448      17.724236            33.988684\n",
       "5.0       0.255017      17.768730            34.023747\n",
       "6.0       0.252016      17.326262            33.578278\n",
       "7.0       0.244077      17.710189            33.954266\n",
       "8.0       0.231901      17.563369            33.795270\n",
       "9.0       0.232287      17.641304            33.873590\n",
       "10.0      0.240127      17.614474            33.854601"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['bias_sq'] = df['bias']**2\n",
    "irreductible_error = 16\n",
    "df['expected_test_error'] = df['bias_sq'] + df['variance'] + irreductible_error\n",
    "overall_results = df.groupby(\"K\").mean().rename(columns={\"bias_sq\": \"bias_sq_mean\", \"variance\": \"variance_mean\"})\n",
    "overall_results = overall_results[[\"bias_sq_mean\", \"variance_mean\", \"expected_test_error\"]]\n",
    "overall_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tUsing overall_results, plot the mean squared bias, mean variance, and expected test error on the same axes as a function of K. Based on this plot, what is the optimal value of K?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_context(\"paper\")\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(overall_results.index, overall_results[\"bias_sq_mean\"], label=\"$Bias^2$\")\n",
    "plt.plot(overall_results.index, overall_results[\"variance_mean\"], label=\"Variance\")\n",
    "plt.plot(overall_results.index, overall_results[\"expected_test_error\"], label=\"Expected Test Error\")\n",
    "\n",
    "plt.title(\"Bias-Variance Tradeoff\")\n",
    "plt.xlabel(\"K\")\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is rather surprising, it appears as though there are little to no changes in error for all K. We have ourselves full with this faulty dataset. Maybe KNN isn't the best model for our case. But let's explore some more and see if we miss something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE:  (6174, 5)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6174 entries, 0 to 6173\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   K         6174 non-null   float64\n",
      " 1   X1        6174 non-null   float64\n",
      " 2   X2        6174 non-null   float64\n",
      " 3   bias      6174 non-null   float64\n",
      " 4   variance  6174 non-null   float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 241.3 KB\n",
      "INFO:  None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>bias</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>16.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.140</td>\n",
       "      <td>12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.109</td>\n",
       "      <td>15.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-0.566</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     K   X1    X2   bias  variance\n",
       "0  1.0  0.0   0.0 -0.250      16.2\n",
       "1  1.0  0.0  10.0  0.140      12.2\n",
       "2  1.0  0.0  20.0 -0.523      20.4\n",
       "3  1.0  0.0  30.0  0.109      15.6\n",
       "4  1.0  0.0  40.0 -0.566      21.4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pyreadr.read_r('training_results_summary.rds')\n",
    "df = result[None]\n",
    "print(\"SHAPE: \", df.shape)\n",
    "print(\"INFO: \", df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "K             10\n",
       "X1             1\n",
       "X2            10\n",
       "bias        6174\n",
       "variance    6173\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait, isn't his field a 200 by 200 field. So there should at least be $\\frac{1}{10}(200 \\times 200)$ different combinations of X1 and X2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
